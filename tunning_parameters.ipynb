{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tunning_parameters.ipynb","provenance":[],"mount_file_id":"1--ps7d0jqpQXQv4UmX7wn5Vi_A22Jqet","authorship_tag":"ABX9TyO43yt5ZeBqlNoXfyeMua9j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Zd9X9I7_4_im"},"source":["## Mounting"]},{"cell_type":"code","metadata":{"id":"OcgV_AQc0gUV","executionInfo":{"status":"ok","timestamp":1604822201918,"user_tz":-120,"elapsed":638,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"da7cf789-1c4d-47b6-bddd-772dfaa621d2","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/My Drive/Colab Notebooks/PRML/Assignment_1"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/Colab Notebooks/PRML/Assignment_1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5bVvrpC95DDt"},"source":["## Import packages + declare paths"]},{"cell_type":"code","metadata":{"id":"8o7vzFsE1KwX","executionInfo":{"status":"ok","timestamp":1604920325026,"user_tz":-120,"elapsed":5703,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"3488244c-016c-434b-a365-47bebee4ce41","colab":{"base_uri":"https://localhost:8080/"}},"source":["%matplotlib inline\n","!pip install ipython-autotime\n","%load_ext autotime\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import stats\n","from sklearn.utils import shuffle\n","import os\n","from PIL import Image\n","import time\n","\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.layers import Flatten, Dense, Conv2D, Dropout, MaxPool2D, BatchNormalization\n","from tensorflow.keras import optimizers\n","from keras.regularizers import l1, l2, l1_l2\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","IMG_TRAIN_PATH = '/content/drive/My Drive/Colab Notebooks/PRML/Assignment_1/train'\n","DATA_NP_PATH = '/content/drive/My Drive/Colab Notebooks/PRML/Assignment_1/np_data'\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting ipython-autotime\n","  Downloading https://files.pythonhosted.org/packages/3f/58/a4a65efcce5c81a67b6893ade862736de355a3a718af5533d30c991831ce/ipython_autotime-0.2.0-py2.py3-none-any.whl\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (50.3.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.2.0\n","time: 1.99 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wDlOFIQl5MRW"},"source":["## Function to load training data"]},{"cell_type":"code","metadata":{"id":"kzjMVyQQ3Qk5","executionInfo":{"status":"ok","timestamp":1604920326580,"user_tz":-120,"elapsed":687,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"79f8e76b-da23-4f4f-8c0b-03a25f2c86ee","colab":{"base_uri":"https://localhost:8080/"}},"source":["def load_data_numpy(dir):\n","    data_dir = os.path.join(dir, \"data_train.npy\")\n","    label_dir = os.path.join(dir, \"label_train.npy\")\n","    return np.load(data_dir), np.load(label_dir)\n","\n","\n","def load_data_image(dir):\n","    LABEL_LIST = [10, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","\n","    X = []\n","    y_onehot = np.zeros((60000, 10))\n","\n","    for num in range(10):\n","        sub_dir = os.path.join(dir, str(LABEL_LIST[num]))\n","        for img_dir in os.listdir(sub_dir):\n","            img = Image.open(os.path.join(sub_dir, img_dir))\n","            array_img = np.array(img)\n","            X.append(np.array(img))\n","\n","        y_onehot[6000*(num):6000*(num+1), num] = 1\n","\n","        # Show example of number\n","        # img.show(title=str(num+1))\n","        plt.figure()\n","        plt.title(str(LABEL_LIST[num]))\n","        plt.imshow(array_img)\n","        plt.show()\n","\n","    X = np.reshape(np.array(X), (60000, 28, 28, 1))\n","    X_shuffle, y_shuffle = shuffle(X, y_onehot, random_state=1)\n","\n","    np.save('data_train.npy', X_shuffle)\n","    np.save('label_train.npy', y_shuffle)\n","\n","    return X_shuffle, y_shuffle"],"execution_count":3,"outputs":[{"output_type":"stream","text":["time: 24.8 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x8BelX8e318-","executionInfo":{"status":"ok","timestamp":1604920350369,"user_tz":-120,"elapsed":4648,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"3d6fa0b9-e885-4e9c-b9d9-edae0ff4e827","colab":{"base_uri":"https://localhost:8080/"}},"source":["X,y = load_data_numpy(DATA_NP_PATH)\n","print(X.shape)\n","print(y.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(60000, 28, 28, 1)\n","(60000, 10)\n","time: 4 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"On3X3onQ4ATP","executionInfo":{"status":"ok","timestamp":1604920351342,"user_tz":-120,"elapsed":379,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"7ef9dda2-3fb3-4fee-e0c5-b6824cdb2680","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_train = X[:50000, :, :]\n","y_train = y[:50000, :]\n","\n","X_small = X_train[:1000, :, :]\n","y_small = y[:1000, :]\n","\n","X_test = X[50000:, :, :]\n","y_test = y[50000:, :]"],"execution_count":6,"outputs":[{"output_type":"stream","text":["time: 1.86 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"imDFHZMr42b7"},"source":["# Load evaluation data"]},{"cell_type":"code","metadata":{"id":"GteTUeCh4sRV","executionInfo":{"status":"ok","timestamp":1604920354565,"user_tz":-120,"elapsed":624,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"f21923fb-8016-4f05-ebb8-404aa914a756","colab":{"base_uri":"https://localhost:8080/"}},"source":["def load_eval_data_numpy(dir):\n","    data_dir = os.path.join(dir, \"eval_data.npy\") \n","    return np.load(data_dir)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["time: 1.3 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OEhGsPLT4wbl","executionInfo":{"status":"ok","timestamp":1604920358702,"user_tz":-120,"elapsed":2970,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"974897f6-df4a-4bf1-efac-e5ec4149cfe7","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_eval = load_eval_data_numpy(DATA_NP_PATH)\n","print(X_eval.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(10000, 28, 28, 1)\n","time: 2 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ukfoVamF5S2G"},"source":["# CNN"]},{"cell_type":"code","metadata":{"id":"aW_EqQE34QS7","executionInfo":{"status":"ok","timestamp":1604922068223,"user_tz":-120,"elapsed":649,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"f1943192-b6bd-471b-b2e0-9c527d8074cb","colab":{"base_uri":"https://localhost:8080/"}},"source":["def build_CNN(reg):\n","    model_cnn = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n","        Conv2D(32, (3, 3), activation='relu'),\n","        MaxPool2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        #Dropout(0.25),\n","\n","        Conv2D(64, (3, 3), activation='relu', padding='same'),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPool2D(pool_size=(2, 2)),\n","        BatchNormalization(),\n","        #Dropout(0.25),\n","        \n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        #Dropout(0.5),\n","        Dense(10, activation='softmax', activity_regularizer=l2(reg))\n","    ])\n","    #Adam, batch_size, #nesterov=True, momentum=0.9\n","\n","    opt_cnn = optimizers.Adam(learning_rate=1e-4)\n","    # good learning_rate = 1e-4\n","    model_cnn.compile(optimizer=opt_cnn, loss=CategoricalCrossentropy(), metrics=['accuracy'])\n","    model_cnn.summary()\n","\n","    return model_cnn"],"execution_count":35,"outputs":[{"output_type":"stream","text":["time: 17.2 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BBtLDBfa4eWF","executionInfo":{"status":"ok","timestamp":1604824772260,"user_tz":-120,"elapsed":1166323,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"36a0d708-1662-418d-fde5-2a23b619dad5","colab":{"base_uri":"https://localhost:8080/"}},"source":["model_cnn = build_CNN(1e-4)\n","model_cnn.fit(X, y, validation_split=0.2, epochs=200, verbose=1)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1600)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               819712    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","Epoch 1/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.7284 - accuracy: 0.7528 - val_loss: 0.2984 - val_accuracy: 0.8991\n","Epoch 2/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.1245 - accuracy: 0.9615 - val_loss: 0.1099 - val_accuracy: 0.9632\n","Epoch 3/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0595 - accuracy: 0.9814 - val_loss: 0.0816 - val_accuracy: 0.9735\n","Epoch 4/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0898 - val_accuracy: 0.9707\n","Epoch 5/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.1954 - val_accuracy: 0.9397\n","Epoch 6/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0871 - val_accuracy: 0.9719\n","Epoch 7/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0688 - val_accuracy: 0.9780\n","Epoch 8/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0419 - val_accuracy: 0.9868\n","Epoch 9/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0426 - val_accuracy: 0.9869\n","Epoch 10/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0628 - val_accuracy: 0.9833\n","Epoch 11/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0405 - val_accuracy: 0.9871\n","Epoch 12/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1013 - val_accuracy: 0.9722\n","Epoch 13/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0526 - val_accuracy: 0.9857\n","Epoch 14/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0694 - val_accuracy: 0.9804\n","Epoch 15/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1118 - val_accuracy: 0.9720\n","Epoch 16/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0372 - val_accuracy: 0.9894\n","Epoch 17/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0624 - val_accuracy: 0.9834\n","Epoch 18/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0695 - val_accuracy: 0.9802\n","Epoch 19/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0393 - val_accuracy: 0.9888\n","Epoch 20/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0542 - val_accuracy: 0.9870\n","Epoch 21/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0499 - val_accuracy: 0.9856\n","Epoch 22/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0386 - val_accuracy: 0.9899\n","Epoch 23/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0481 - val_accuracy: 0.9877\n","Epoch 24/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0463 - val_accuracy: 0.9896\n","Epoch 25/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0453 - val_accuracy: 0.9902\n","Epoch 26/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0369 - val_accuracy: 0.9918\n","Epoch 27/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0373 - val_accuracy: 0.9905\n","Epoch 28/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1071 - val_accuracy: 0.9760\n","Epoch 29/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0392 - val_accuracy: 0.9907\n","Epoch 30/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.0347 - val_accuracy: 0.9922\n","Epoch 31/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0541 - val_accuracy: 0.9877\n","Epoch 32/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0433 - val_accuracy: 0.9903\n","Epoch 33/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0412 - val_accuracy: 0.9901\n","Epoch 34/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0274 - val_accuracy: 0.9933\n","Epoch 35/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0389 - val_accuracy: 0.9896\n","Epoch 36/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0509 - val_accuracy: 0.9870\n","Epoch 37/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0301 - val_accuracy: 0.9930\n","Epoch 38/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0292 - val_accuracy: 0.9924\n","Epoch 39/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0353 - val_accuracy: 0.9923\n","Epoch 40/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0318 - val_accuracy: 0.9929\n","Epoch 41/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0272 - val_accuracy: 0.9937\n","Epoch 42/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0457 - val_accuracy: 0.9887\n","Epoch 43/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0272 - val_accuracy: 0.9939\n","Epoch 44/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1299 - val_accuracy: 0.9696\n","Epoch 45/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0233 - val_accuracy: 0.9944\n","Epoch 46/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0362 - val_accuracy: 0.9920\n","Epoch 47/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0287 - val_accuracy: 0.9937\n","Epoch 48/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0428 - val_accuracy: 0.9916\n","Epoch 49/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0401 - val_accuracy: 0.9914\n","Epoch 50/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0303 - val_accuracy: 0.9920\n","Epoch 51/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0318 - val_accuracy: 0.9919\n","Epoch 52/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.1814e-04 - accuracy: 0.9998 - val_loss: 0.0275 - val_accuracy: 0.9934\n","Epoch 53/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0288 - val_accuracy: 0.9930\n","Epoch 54/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0208 - val_accuracy: 0.9950\n","Epoch 55/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0395 - val_accuracy: 0.9901\n","Epoch 56/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0270 - val_accuracy: 0.9942\n","Epoch 57/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.5386e-04 - accuracy: 0.9998 - val_loss: 0.0210 - val_accuracy: 0.9952\n","Epoch 58/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0235 - val_accuracy: 0.9943\n","Epoch 59/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.9279e-04 - accuracy: 0.9997 - val_loss: 0.0239 - val_accuracy: 0.9943\n","Epoch 60/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0279 - val_accuracy: 0.9927\n","Epoch 61/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0301 - val_accuracy: 0.9937\n","Epoch 62/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0235 - val_accuracy: 0.9948\n","Epoch 63/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.8161e-04 - accuracy: 0.9998 - val_loss: 0.0247 - val_accuracy: 0.9949\n","Epoch 64/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0358 - val_accuracy: 0.9928\n","Epoch 65/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0244 - val_accuracy: 0.9946\n","Epoch 66/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.3323e-04 - accuracy: 0.9998 - val_loss: 0.0241 - val_accuracy: 0.9948\n","Epoch 67/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0334 - val_accuracy: 0.9933\n","Epoch 68/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0249 - val_accuracy: 0.9942\n","Epoch 69/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0261 - val_accuracy: 0.9946\n","Epoch 70/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0409 - val_accuracy: 0.9902\n","Epoch 71/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0194 - val_accuracy: 0.9956\n","Epoch 72/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.4421e-04 - accuracy: 0.9998 - val_loss: 0.0196 - val_accuracy: 0.9945\n","Epoch 73/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0213 - val_accuracy: 0.9952\n","Epoch 74/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0274 - val_accuracy: 0.9937\n","Epoch 75/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.0207e-04 - accuracy: 0.9998 - val_loss: 0.0245 - val_accuracy: 0.9946\n","Epoch 76/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.5013e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9953\n","Epoch 77/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.1301e-04 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9954\n","Epoch 78/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0286 - val_accuracy: 0.9938\n","Epoch 79/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.6548e-04 - accuracy: 0.9997 - val_loss: 0.0214 - val_accuracy: 0.9957\n","Epoch 80/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0221 - val_accuracy: 0.9952\n","Epoch 81/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0259 - val_accuracy: 0.9945\n","Epoch 82/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0249 - val_accuracy: 0.9950\n","Epoch 83/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0255 - val_accuracy: 0.9939\n","Epoch 84/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.5355e-04 - accuracy: 0.9998 - val_loss: 0.0255 - val_accuracy: 0.9931\n","Epoch 85/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.1212e-04 - accuracy: 0.9999 - val_loss: 0.0181 - val_accuracy: 0.9957\n","Epoch 86/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0224 - val_accuracy: 0.9942\n","Epoch 87/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0495 - val_accuracy: 0.9915\n","Epoch 88/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.3275e-04 - accuracy: 0.9997 - val_loss: 0.0236 - val_accuracy: 0.9948\n","Epoch 89/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.1790e-04 - accuracy: 0.9998 - val_loss: 0.0619 - val_accuracy: 0.9897\n","Epoch 90/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0340 - val_accuracy: 0.9937\n","Epoch 91/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.9172e-04 - accuracy: 0.9998 - val_loss: 0.0223 - val_accuracy: 0.9948\n","Epoch 92/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0213 - val_accuracy: 0.9952\n","Epoch 93/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.9590e-04 - accuracy: 0.9999 - val_loss: 0.0177 - val_accuracy: 0.9960\n","Epoch 94/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.5510e-04 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9952\n","Epoch 95/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.0591e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9942\n","Epoch 96/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0600 - val_accuracy: 0.9883\n","Epoch 97/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0276 - val_accuracy: 0.9950\n","Epoch 98/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0234 - val_accuracy: 0.9955\n","Epoch 99/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.5225e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9952\n","Epoch 100/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0430 - val_accuracy: 0.9927\n","Epoch 101/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0298 - val_accuracy: 0.9950\n","Epoch 102/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0224 - val_accuracy: 0.9948\n","Epoch 103/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 5.6612e-04 - accuracy: 0.9999 - val_loss: 0.0236 - val_accuracy: 0.9950\n","Epoch 104/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.4764e-04 - accuracy: 0.9998 - val_loss: 0.0208 - val_accuracy: 0.9952\n","Epoch 105/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.3009e-04 - accuracy: 0.9998 - val_loss: 0.0314 - val_accuracy: 0.9937\n","Epoch 106/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0275 - val_accuracy: 0.9958\n","Epoch 107/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.6080e-04 - accuracy: 0.9998 - val_loss: 0.0328 - val_accuracy: 0.9941\n","Epoch 108/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0477 - val_accuracy: 0.9921\n","Epoch 109/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.5599e-04 - accuracy: 0.9999 - val_loss: 0.0301 - val_accuracy: 0.9946\n","Epoch 110/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.3862e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9937\n","Epoch 111/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.8091e-04 - accuracy: 0.9998 - val_loss: 0.0319 - val_accuracy: 0.9949\n","Epoch 112/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0394 - val_accuracy: 0.9935\n","Epoch 113/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.8763e-04 - accuracy: 0.9998 - val_loss: 0.0272 - val_accuracy: 0.9958\n","Epoch 114/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0267 - val_accuracy: 0.9952\n","Epoch 115/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.7754e-04 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9967\n","Epoch 116/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0342 - val_accuracy: 0.9933\n","Epoch 117/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0233 - val_accuracy: 0.9960\n","Epoch 118/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.9966e-04 - accuracy: 0.9998 - val_loss: 0.0627 - val_accuracy: 0.9902\n","Epoch 119/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0439 - val_accuracy: 0.9921\n","Epoch 120/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.0520e-04 - accuracy: 0.9998 - val_loss: 0.0265 - val_accuracy: 0.9948\n","Epoch 121/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.4078e-04 - accuracy: 0.9999 - val_loss: 0.0266 - val_accuracy: 0.9951\n","Epoch 122/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0196 - val_accuracy: 0.9961\n","Epoch 123/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0299 - val_accuracy: 0.9942\n","Epoch 124/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.4890e-04 - accuracy: 0.9998 - val_loss: 0.0341 - val_accuracy: 0.9937\n","Epoch 125/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.4789e-04 - accuracy: 0.9998 - val_loss: 0.0202 - val_accuracy: 0.9956\n","Epoch 126/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.8975e-04 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9936\n","Epoch 127/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0274 - val_accuracy: 0.9942\n","Epoch 128/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0185 - val_accuracy: 0.9958\n","Epoch 129/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.1215e-04 - accuracy: 0.9997 - val_loss: 0.0153 - val_accuracy: 0.9967\n","Epoch 130/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.9454e-04 - accuracy: 0.9999 - val_loss: 0.0153 - val_accuracy: 0.9967\n","Epoch 131/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.1445e-04 - accuracy: 0.9999 - val_loss: 0.0192 - val_accuracy: 0.9957\n","Epoch 132/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0193 - val_accuracy: 0.9958\n","Epoch 133/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.5606e-04 - accuracy: 0.9999 - val_loss: 0.0234 - val_accuracy: 0.9952\n","Epoch 134/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.3778e-04 - accuracy: 0.9998 - val_loss: 0.0202 - val_accuracy: 0.9958\n","Epoch 135/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.8188e-04 - accuracy: 0.9998 - val_loss: 0.0436 - val_accuracy: 0.9917\n","Epoch 136/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.3454e-04 - accuracy: 0.9997 - val_loss: 0.0216 - val_accuracy: 0.9964\n","Epoch 137/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.6904e-04 - accuracy: 0.9997 - val_loss: 0.0179 - val_accuracy: 0.9967\n","Epoch 138/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.9499e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9963\n","Epoch 139/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.8196e-04 - accuracy: 0.9999 - val_loss: 0.0483 - val_accuracy: 0.9914\n","Epoch 140/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.0454e-04 - accuracy: 0.9999 - val_loss: 0.0197 - val_accuracy: 0.9957\n","Epoch 141/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 5.7719e-04 - accuracy: 0.9998 - val_loss: 0.0247 - val_accuracy: 0.9951\n","Epoch 142/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.7864e-04 - accuracy: 0.9999 - val_loss: 0.0234 - val_accuracy: 0.9953\n","Epoch 143/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.2250e-04 - accuracy: 0.9999 - val_loss: 0.0244 - val_accuracy: 0.9956\n","Epoch 144/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0259 - val_accuracy: 0.9959\n","Epoch 145/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.9653e-04 - accuracy: 0.9999 - val_loss: 0.0343 - val_accuracy: 0.9937\n","Epoch 146/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0297 - val_accuracy: 0.9942\n","Epoch 147/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 5.1955e-04 - accuracy: 0.9999 - val_loss: 0.0205 - val_accuracy: 0.9959\n","Epoch 148/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0263 - val_accuracy: 0.9951\n","Epoch 149/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.0391e-04 - accuracy: 0.9998 - val_loss: 0.0500 - val_accuracy: 0.9908\n","Epoch 150/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.2469e-04 - accuracy: 0.9998 - val_loss: 0.0203 - val_accuracy: 0.9967\n","Epoch 151/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.8112e-04 - accuracy: 0.9999 - val_loss: 0.0212 - val_accuracy: 0.9973\n","Epoch 152/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.6660e-04 - accuracy: 0.9998 - val_loss: 0.0225 - val_accuracy: 0.9959\n","Epoch 153/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.8794e-04 - accuracy: 0.9999 - val_loss: 0.0200 - val_accuracy: 0.9966\n","Epoch 154/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.5916e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9955\n","Epoch 155/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0438 - val_accuracy: 0.9931\n","Epoch 156/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.2492e-04 - accuracy: 0.9998 - val_loss: 0.0301 - val_accuracy: 0.9948\n","Epoch 157/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.5419e-04 - accuracy: 0.9998 - val_loss: 0.0235 - val_accuracy: 0.9954\n","Epoch 158/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.5304e-04 - accuracy: 0.9997 - val_loss: 0.0280 - val_accuracy: 0.9953\n","Epoch 159/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 5.5061e-04 - accuracy: 0.9999 - val_loss: 0.0223 - val_accuracy: 0.9960\n","Epoch 160/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0287 - val_accuracy: 0.9945\n","Epoch 161/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.4347e-04 - accuracy: 0.9999 - val_loss: 0.0237 - val_accuracy: 0.9952\n","Epoch 162/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.3129e-04 - accuracy: 0.9998 - val_loss: 0.0235 - val_accuracy: 0.9967\n","Epoch 163/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.7593e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9965\n","Epoch 164/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.6260e-04 - accuracy: 0.9999 - val_loss: 0.0245 - val_accuracy: 0.9952\n","Epoch 165/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0247 - val_accuracy: 0.9948\n","Epoch 166/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.7616e-04 - accuracy: 0.9999 - val_loss: 0.0190 - val_accuracy: 0.9966\n","Epoch 167/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.5181e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9968\n","Epoch 168/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.4504e-04 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9943\n","Epoch 169/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0261 - val_accuracy: 0.9952\n","Epoch 170/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0214 - val_accuracy: 0.9962\n","Epoch 171/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.0639e-04 - accuracy: 0.9998 - val_loss: 0.0236 - val_accuracy: 0.9958\n","Epoch 172/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.4854e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9973\n","Epoch 173/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.2519e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9969\n","Epoch 174/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0293 - val_accuracy: 0.9950\n","Epoch 175/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.6211e-04 - accuracy: 0.9998 - val_loss: 0.0201 - val_accuracy: 0.9968\n","Epoch 176/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.7777e-04 - accuracy: 0.9999 - val_loss: 0.0966 - val_accuracy: 0.9843\n","Epoch 177/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.9757e-04 - accuracy: 0.9997 - val_loss: 0.0177 - val_accuracy: 0.9959\n","Epoch 178/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.1445e-04 - accuracy: 0.9998 - val_loss: 0.0217 - val_accuracy: 0.9962\n","Epoch 179/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.5684e-04 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9953\n","Epoch 180/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 5.4219e-04 - accuracy: 0.9999 - val_loss: 0.0163 - val_accuracy: 0.9977\n","Epoch 181/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.0877e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9979\n","Epoch 182/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 9.1101e-04 - accuracy: 0.9998 - val_loss: 0.0309 - val_accuracy: 0.9944\n","Epoch 183/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0250 - val_accuracy: 0.9953\n","Epoch 184/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.7852e-04 - accuracy: 0.9999 - val_loss: 0.0142 - val_accuracy: 0.9974\n","Epoch 185/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.2488e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9977\n","Epoch 186/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.7918e-04 - accuracy: 0.9998 - val_loss: 0.0190 - val_accuracy: 0.9962\n","Epoch 187/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.7827e-04 - accuracy: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9980\n","Epoch 188/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.1774e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9979\n","Epoch 189/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.2598e-04 - accuracy: 0.9998 - val_loss: 0.0444 - val_accuracy: 0.9937\n","Epoch 190/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.0291e-04 - accuracy: 0.9998 - val_loss: 0.0260 - val_accuracy: 0.9950\n","Epoch 191/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 1.2997e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9972\n","Epoch 192/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.9754e-04 - accuracy: 0.9999 - val_loss: 0.0323 - val_accuracy: 0.9948\n","Epoch 193/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.7912e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9962\n","Epoch 194/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 7.6819e-04 - accuracy: 0.9998 - val_loss: 0.0239 - val_accuracy: 0.9957\n","Epoch 195/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 3.5943e-04 - accuracy: 0.9999 - val_loss: 0.0424 - val_accuracy: 0.9934\n","Epoch 196/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.6615e-04 - accuracy: 0.9999 - val_loss: 0.0268 - val_accuracy: 0.9953\n","Epoch 197/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 6.3536e-04 - accuracy: 0.9998 - val_loss: 0.0268 - val_accuracy: 0.9957\n","Epoch 198/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 4.8371e-04 - accuracy: 0.9998 - val_loss: 0.0392 - val_accuracy: 0.9939\n","Epoch 199/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 8.3259e-04 - accuracy: 0.9998 - val_loss: 0.0251 - val_accuracy: 0.9953\n","Epoch 200/200\n","1500/1500 [==============================] - 6s 4ms/step - loss: 2.7164e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9966\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f89a372a5c0>"]},"metadata":{"tags":[]},"execution_count":42},{"output_type":"stream","text":["time: 19min 25s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"73HW38TsAIQu"},"source":["## Check on training set X,y"]},{"cell_type":"code","metadata":{"id":"xL3nwQHUAH4f","executionInfo":{"status":"ok","timestamp":1604824812620,"user_tz":-120,"elapsed":5274,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"86ecb433-ab82-4beb-c32d-859026b5e26c","colab":{"base_uri":"https://localhost:8080/"}},"source":["test_loss, test_acc = model_cnn.evaluate(X, y)\n","print(\"Loss:\", test_loss, \"Accuracy:\", test_acc)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["1875/1875 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9993\n","Loss: 0.004469430074095726 Accuracy: 0.9993166923522949\n","time: 4.25 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OCXQGUll87ff"},"source":["## Tunning parameters"]},{"cell_type":"code","metadata":{"id":"ObOZ-xs64n8F","executionInfo":{"status":"ok","timestamp":1604837569046,"user_tz":-120,"elapsed":12747511,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"53d422b1-4841-4dc3-bbd6-b1ca83b5c4f0","colab":{"base_uri":"https://localhost:8080/"}},"source":["reg_list = {}\n","for i in range(15): \n","    if i<5:\n","        reg = np.random.uniform(5e-1, 1e-1)\n","    elif i<10:\n","        reg = np.random.uniform(1e-1, 5e-2)\n","    else:\n","        reg = np.random.uniform(5e-2, 1e-2)\n","    \n","    model_cnn = build_CNN(reg)\n","    history = model_cnn.fit(X, y, validation_split=0.2, epochs=200, verbose=0)  # epochs=150-200 is good\n","    reg_list[reg] = [history.history['loss'][-1], history.history['val_accuracy'][-1]]\n","    print(i, reg, reg_list[reg])"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               819712    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","0 0.3958082644218162 [0.39583179354667664, 0.9974166750907898]\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_10 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               819712    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","1 0.38610197665313023 [0.38619372248649597, 0.9919166564941406]\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_14 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 512)               819712    \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","2 0.4907644421975247 [0.49129772186279297, 0.9958333373069763]\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_18 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 512)               819712    \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","3 0.19728555264557324 [0.19797036051750183, 0.9972500205039978]\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_22 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","4 0.3207777530579903 [0.3207812011241913, 0.996999979019165]\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_26 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_6 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","5 0.09229101876107958 [0.09285184741020203, 0.9951666593551636]\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_30 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_31 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_32 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_33 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","6 0.0795385953758415 [0.07983125746250153, 0.9947500228881836]\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_34 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_35 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_36 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_37 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","7 0.09289983160548884 [0.09357023984193802, 0.9950833320617676]\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_38 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_39 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_19 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_40 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_41 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_20 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","8 0.08449201901420669 [0.08452219516038895, 0.9975000023841858]\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_42 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_43 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_21 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_44 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_45 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_22 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 1600)              0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","9 0.08514350588614028 [0.08592110127210617, 0.996666669845581]\n","Model: \"sequential_11\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_46 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_47 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_23 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_49 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_24 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_11 (Flatten)         (None, 1600)              0         \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","10 0.035985338926663446 [0.03654631972312927, 0.9948333501815796]\n","Model: \"sequential_12\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_50 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_51 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_25 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_52 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_53 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_26 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_12 (Flatten)         (None, 1600)              0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_25 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","11 0.019316155990086303 [0.020338408648967743, 0.9950000047683716]\n","Model: \"sequential_13\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_54 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_55 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_27 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_56 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_57 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_28 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_13 (Flatten)         (None, 1600)              0         \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","12 0.0447015462962697 [0.04593914374709129, 0.9965833425521851]\n","Model: \"sequential_14\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_58 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_59 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_29 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_60 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_61 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_30 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 1600)              0         \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","13 0.04108993030978673 [0.04219615086913109, 0.9940000176429749]\n","Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_62 (Conv2D)           (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","conv2d_63 (Conv2D)           (None, 26, 26, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_31 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 13, 13, 32)        128       \n","_________________________________________________________________\n","conv2d_64 (Conv2D)           (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","conv2d_65 (Conv2D)           (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_32 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 5, 5, 64)          256       \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 1600)              0         \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 512)               819712    \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 890,218\n","Trainable params: 890,026\n","Non-trainable params: 192\n","_________________________________________________________________\n","14 0.04481673835428694 [0.04557875171303749, 0.9965000152587891]\n","time: 3h 32min 26s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w8bL26581pDT"},"source":["## Applied a suitable regularization value"]},{"cell_type":"code","metadata":{"id":"zlTDSNPmA4og"},"source":["model_cnn = build_CNN(1e-4)\n","model_cnn.fit(X, y, validation_split=0.2, epochs=200, verbose=0)\n","import h5py\n","model_cnn.save(\"cnn_model_9_11.h5\")\n","from tensorflow.keras.models import load_model\n","new_model = load_model(\"/content/drive/My Drive/Colab Notebooks/PRML/Assignment_1/cnn_model.h5\")\n","new_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxCfxWZrx_w9","executionInfo":{"status":"ok","timestamp":1604920393776,"user_tz":-120,"elapsed":12027,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"f1dd2d89-a15a-4578-8eba-66127729283d","colab":{"base_uri":"https://localhost:8080/"}},"source":["test_loss, test_acc = new_model.evaluate(X, y)\n","print(\"Loss:\", test_loss, \"Accuracy:\", test_acc)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1875/1875 [==============================] - 5s 2ms/step - loss: 0.0241 - accuracy: 0.9991\n","Loss: 0.024081509560346603 Accuracy: 0.9991000294685364\n","time: 11.4 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GDeJpdXf2KHx","executionInfo":{"status":"ok","timestamp":1604920396608,"user_tz":-120,"elapsed":1158,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"afa76d3e-9f9a-4d22-c55c-4a12844e0ed8","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_prob = new_model.predict(X_eval)\n","print(y_prob.shape)\n","y_eval = np.argmax(y_prob,axis=1)\n","print(y_eval.shape)\n","print(y_eval[:10])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(10000, 10)\n","(10000,)\n","[9 1 1 4 7 3 2 3 5 7]\n","time: 512 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sJJkLPV0vuK3"},"source":["## Change labels 0 to 10"]},{"cell_type":"code","metadata":{"id":"ooae1fypEPl1","executionInfo":{"status":"ok","timestamp":1604921282830,"user_tz":-120,"elapsed":617,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"6ee6fd5c-42f5-4eb9-8e9d-aee87bb81ce1","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_eval[y_eval == 0] = 10\n","list_dir = os.listdir(os.path.join(os.getcwd(),'evaluate/'))\n","print(len(list_dir))\n","print(list_dir[:20]) # listdir does not list directories in correct order !"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[ 1  2  3  4  5  6  7  8  9 10]\n","[ 9  1  1  4  7  3  2  3  5  7 10  3  7  7  7  9  4 10  4  6]\n","[ 1  2  3  4  5  6  7  8  9 10]\n","[ 9  1  1  4  7  3  2  3  5  7 10  3  7  7  7  9  4 10  4  6]\n","10000\n","['09951.jpg', '09557.jpg', '09208.jpg', '09325.jpg', '09394.jpg', '09531.jpg', '09578.jpg', '09185.jpg', '09611.jpg', '09903.jpg', '09503.jpg', '09804.jpg', '09344.jpg', '09184.jpg', '09299.jpg', '09599.jpg', '09916.jpg', '09132.jpg', '09957.jpg', '09832.jpg']\n","time: 55.8 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"At6zEpJr9UOd"},"source":["## Save result"]},{"cell_type":"code","metadata":{"id":"DRbMZ_ic9TW_","executionInfo":{"status":"ok","timestamp":1604924250483,"user_tz":-120,"elapsed":657,"user":{"displayName":"Van Thanh Trung","photoUrl":"","userId":"04909438245901289423"}},"outputId":"491c8d2e-a17a-40e1-9fe4-d9f167e5e64c","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd /content/drive/My\\ Drive/Colab\\ Notebooks/PRML/Assignment_1/\n","img_id = np.arange(0,10000,1)\n","print(y_eval[:20])\n","result = np.column_stack([img_id,y_eval])\n","print(result[:20])\n","print('unique values: ',np.unique(result[:,1]))\n","import pandas as pd\n","result = pd.DataFrame(data=result,columns=['Id','Category']).astype(int)\n","result.to_csv('result_pd.csv',index=False,sep=';')\n"],"execution_count":50,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/PRML/Assignment_1\n","[ 9  1  1  4  7  3  2  3  5  7 10  3  7  7  7  9  4 10  4  6]\n","[[ 0  9]\n"," [ 1  1]\n"," [ 2  1]\n"," [ 3  4]\n"," [ 4  7]\n"," [ 5  3]\n"," [ 6  2]\n"," [ 7  3]\n"," [ 8  5]\n"," [ 9  7]\n"," [10 10]\n"," [11  3]\n"," [12  7]\n"," [13  7]\n"," [14  7]\n"," [15  9]\n"," [16  4]\n"," [17 10]\n"," [18  4]\n"," [19  6]]\n","unique values:  [ 1  2  3  4  5  6  7  8  9 10]\n","time: 31.5 ms\n"],"name":"stdout"}]}]}